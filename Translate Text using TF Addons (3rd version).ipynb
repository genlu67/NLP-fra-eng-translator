{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17e67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\App\\Miniconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os \n",
    "\n",
    "import time\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d9605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'fra-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip',\n",
    "    extract=True, cache_dir = \"D:/Programming/Python/NLP tutorial\")\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9730f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    inp = [inp for targ, inp in pairs]\n",
    "    targ = [targ for targ, inp in pairs]\n",
    "\n",
    "    return targ, inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1d3de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il est peut-être impossible d'obtenir un Corpus complètement dénué de fautes, étant donnée la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent, nous pourrions être en mesure de réduire les erreurs.\n"
     ]
    }
   ],
   "source": [
    "targ, inp = load_data(path_to_file)\n",
    "print(inp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b82788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tf_lower_and_split_punct:\n",
    "    def __init__(self, start = True, end = True):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        \n",
    "    def __call__(self, text):\n",
    "        # Split accented characters.\n",
    "        text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "        text = tf.strings.lower(text)\n",
    "        # Keep space, a to z, and select punctuation.\n",
    "        text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "        # Add spaces around punctuation.\n",
    "        text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "        # Strip whitespace.\n",
    "        text = tf.strings.strip(text)\n",
    "        if self.start == True:\n",
    "            text = tf.strings.join(['[START]', text], separator=' ')\n",
    "        if self.end == True:\n",
    "            text = tf.strings.join([text, '[END]'], separator=' ')\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6b2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 5000\n",
    "BUFFER_SIZE = 32000\n",
    "BATCH_SIZE = 64\n",
    "max_input_sequence = 20\n",
    "max_output_sequence = 20\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct(),\n",
    "    max_tokens=max_vocab_size,\n",
    "    output_sequence_length=max_input_sequence)\n",
    "\n",
    "output_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct(),\n",
    "    max_tokens=max_vocab_size,\n",
    "    output_sequence_length=max_output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4af33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_processor.adapt(inp)\n",
    "output_text_processor.adapt(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7872a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data,valid_input_data, train_output_data, valid_output_data = train_test_split(inp, targ, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20897df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_output_data))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_input_data, valid_output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aded68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return (ds\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x, y : (input_text_processor(x), output_text_processor(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "train_batches = make_batches(train_dataset)\n",
    "valid_batches = make_batches(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e012d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
       " array([[  2,  26, 858, ...,   0,   0,   0],\n",
       "        [  2,  11, 327, ...,   0,   0,   0],\n",
       "        [  2,  11, 260, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  2, 151,   1, ...,   0,   0,   0],\n",
       "        [  2,   5,  41, ...,   0,   0,   0],\n",
       "        [  2, 118,  44, ...,   0,   0,   0]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(64, 20), dtype=int64, numpy=\n",
       " array([[  2,   5, 962, ...,   0,   0,   0],\n",
       "        [  2,   1, 160, ...,   0,   0,   0],\n",
       "        [  2,   8, 168, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  2, 338, 615, ...,   0,   0,   0],\n",
       "        [  2,  79, 163, ...,   0,   0,   0],\n",
       "        [  2,  44,   6, ...,   0,   0,   0]], dtype=int64)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_output_batch = next(iter(train_batches))\n",
    "example_input_batch, example_output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3f8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 1024\n",
    "num_examples = 30000\n",
    "steps_per_epoch = num_examples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6098ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm_layer = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                              return_sequences = True,\n",
    "                                              return_state = True,\n",
    "                                              recurrent_initializer = \"glorot_uniform\")\n",
    "        \n",
    "    def call(self, inp, hidden = None):\n",
    "        inp = self.embedding(inp)\n",
    "        output, h, c = self.lstm_layer(inp, initial_state = hidden)\n",
    "        return output, h, c\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return [tf.fill((self.batch_size, self.enc_units), 0.), tf.fill((self.batch_size, self.enc_units), 0.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1737d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
      "Encoder h vecotr shape: (batch size, units) (64, 1024)\n",
      "Encoder c vector shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(max_vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder h vecotr shape: (batch size, units) {}'.format(sample_h.shape))\n",
    "print ('Encoder c vector shape: (batch size, units) {}'.format(sample_c.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0b902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size, attention_type = \"luong\"):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.attention_type = attention_type\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.decoder_rnn_cell = tf.keras.layers.LSTMCell(self.dec_units)\n",
    "        \n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.attention_mechanism = self.build_attention_mechanism(self.dec_units, \n",
    "                                                              None, self.batch_size*[max_input_sequence], self.attention_type)\n",
    "        \n",
    "        self.rnn_cell = self.build_rnn_cell(batch_size)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, \n",
    "                                                sampler=self.sampler, \n",
    "                                                output_layer=self.fc)\n",
    "    def build_rnn_cell(self, batch_size):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnn_cell, \n",
    "                                                self.attention_mechanism, \n",
    "                                                attention_layer_size=self.dec_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_attention_mechanism(self, dec_units, memory, memory_sequence_length, attention_type='luong'):\n",
    "        if(attention_type=='bahdanau'):\n",
    "            return tfa.seq2seq.BahdanauAttention(units=dec_units, \n",
    "                                                 memory=memory, \n",
    "                                                 memory_sequence_length=memory_sequence_length)\n",
    "        else:\n",
    "            return tfa.seq2seq.LuongAttention(units=dec_units, \n",
    "                                              memory=memory, \n",
    "                                              memory_sequence_length=memory_sequence_length)\n",
    "        \n",
    "    def build_initial_state(self, batch_size, encoder_state, dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=batch_size, dtype=dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "        return decoder_initial_state\n",
    "    \n",
    "    def call(self, inputs, initial_state):\n",
    "        x = self.embedding(inputs)\n",
    "        outputs, _, _ = self.decoder(x, initial_state = initial_state,\n",
    "                                    sequence_length = self.batch_size*[max_input_sequence-1])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c905360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Outputs Shape:  (64, 19, 5000)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(max_vocab_size, embedding_dim, units, BATCH_SIZE, 'luong')\n",
    "sample_x = tf.random.uniform((BATCH_SIZE, max_output_sequence))\n",
    "decoder.attention_mechanism.setup_memory(sample_output)\n",
    "initial_state = decoder.build_initial_state(BATCH_SIZE, [sample_h, sample_c], tf.float32)\n",
    "\n",
    "sample_decoder_outputs = decoder(sample_x, initial_state)\n",
    "\n",
    "print(\"Decoder Outputs Shape: \", sample_decoder_outputs.rnn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164c9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "\n",
    "def loss_func(real, pred):\n",
    "    cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = cross_entropy(y_true=real, y_pred=pred)\n",
    "    mask = tf.logical_not(tf.math.equal(real,0))\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf9de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74b21259",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_input = targ[ : , :-1 ]\n",
    "        real = targ[ : , 1: ]\n",
    "        \n",
    "        decoder.attention_mechanism.setup_memory(enc_output)\n",
    "        \n",
    "        decoder_initial_state = decoder.build_initial_state(BATCH_SIZE, [enc_h, enc_c], tf.float32)\n",
    "        pred = decoder(dec_input, decoder_initial_state)\n",
    "        logits = pred.rnn_output\n",
    "        loss = loss_func(real, logits)\n",
    "        \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1446836a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.6351\n",
      "Epoch 1 Batch 100 Loss 2.0005\n",
      "Epoch 1 Batch 200 Loss 1.9528\n",
      "Epoch 1 Batch 300 Loss 1.7715\n",
      "Epoch 1 Batch 400 Loss 1.7637\n",
      "Epoch 1 Loss 1.8907\n",
      "Time taken for 1 epoch 112.73903775215149 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5984\n",
      "Epoch 2 Batch 100 Loss 1.5389\n",
      "Epoch 2 Batch 200 Loss 1.3836\n",
      "Epoch 2 Batch 300 Loss 1.3094\n",
      "Epoch 2 Batch 400 Loss 1.2721\n",
      "Epoch 2 Loss 1.4713\n",
      "Time taken for 1 epoch 103.8940007686615 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2131\n",
      "Epoch 3 Batch 100 Loss 1.3520\n",
      "Epoch 3 Batch 200 Loss 1.4366\n",
      "Epoch 3 Batch 300 Loss 1.2106\n",
      "Epoch 3 Batch 400 Loss 1.2476\n",
      "Epoch 3 Loss 1.2527\n",
      "Time taken for 1 epoch 102.81501579284668 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0833\n",
      "Epoch 4 Batch 100 Loss 1.1070\n",
      "Epoch 4 Batch 200 Loss 0.9935\n",
      "Epoch 4 Batch 300 Loss 0.8472\n",
      "Epoch 4 Batch 400 Loss 0.8427\n",
      "Epoch 4 Loss 1.0250\n",
      "Time taken for 1 epoch 103.36233901977539 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.8946\n",
      "Epoch 5 Batch 100 Loss 0.7434\n",
      "Epoch 5 Batch 200 Loss 0.9022\n",
      "Epoch 5 Batch 300 Loss 0.8958\n",
      "Epoch 5 Batch 400 Loss 0.7533\n",
      "Epoch 5 Loss 0.7523\n",
      "Time taken for 1 epoch 102.19899821281433 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7053\n",
      "Epoch 6 Batch 100 Loss 0.6145\n",
      "Epoch 6 Batch 200 Loss 0.6112\n",
      "Epoch 6 Batch 300 Loss 0.6500\n",
      "Epoch 6 Batch 400 Loss 0.6975\n",
      "Epoch 6 Loss 0.6000\n",
      "Time taken for 1 epoch 104.55660223960876 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4855\n",
      "Epoch 7 Batch 100 Loss 0.4104\n",
      "Epoch 7 Batch 200 Loss 0.4622\n",
      "Epoch 7 Batch 300 Loss 0.4552\n",
      "Epoch 7 Batch 400 Loss 0.4641\n",
      "Epoch 7 Loss 0.5141\n",
      "Time taken for 1 epoch 103.68096709251404 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.3314\n",
      "Epoch 8 Batch 100 Loss 0.4297\n",
      "Epoch 8 Batch 200 Loss 0.5118\n",
      "Epoch 8 Batch 300 Loss 0.4079\n",
      "Epoch 8 Batch 400 Loss 0.5440\n",
      "Epoch 8 Loss 0.4516\n",
      "Time taken for 1 epoch 105.94208240509033 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4184\n",
      "Epoch 9 Batch 100 Loss 0.3821\n",
      "Epoch 9 Batch 200 Loss 0.4776\n",
      "Epoch 9 Batch 300 Loss 0.3713\n",
      "Epoch 9 Batch 400 Loss 0.4345\n",
      "Epoch 9 Loss 0.4046\n",
      "Time taken for 1 epoch 103.02268123626709 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2804\n",
      "Epoch 10 Batch 100 Loss 0.3340\n",
      "Epoch 10 Batch 200 Loss 0.3130\n",
      "Epoch 10 Batch 300 Loss 0.4044\n",
      "Epoch 10 Batch 400 Loss 0.3966\n",
      "Epoch 10 Loss 0.3639\n",
      "Time taken for 1 epoch 103.80358743667603 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2599\n",
      "Epoch 11 Batch 100 Loss 0.2918\n",
      "Epoch 11 Batch 200 Loss 0.3127\n",
      "Epoch 11 Batch 300 Loss 0.4021\n",
      "Epoch 11 Batch 400 Loss 0.3579\n",
      "Epoch 11 Loss 0.3366\n",
      "Time taken for 1 epoch 103.15999579429626 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.2403\n",
      "Epoch 12 Batch 100 Loss 0.2795\n",
      "Epoch 12 Batch 200 Loss 0.3381\n",
      "Epoch 12 Batch 300 Loss 0.3111\n",
      "Epoch 12 Batch 400 Loss 0.2908\n",
      "Epoch 12 Loss 0.3093\n",
      "Time taken for 1 epoch 103.73273086547852 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2722\n",
      "Epoch 13 Batch 100 Loss 0.2452\n",
      "Epoch 13 Batch 200 Loss 0.2346\n",
      "Epoch 13 Batch 300 Loss 0.3116\n",
      "Epoch 13 Batch 400 Loss 0.2910\n",
      "Epoch 13 Loss 0.2882\n",
      "Time taken for 1 epoch 102.91900086402893 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.2582\n",
      "Epoch 14 Batch 100 Loss 0.2898\n",
      "Epoch 14 Batch 200 Loss 0.2823\n",
      "Epoch 14 Batch 300 Loss 0.2422\n",
      "Epoch 14 Batch 400 Loss 0.3404\n",
      "Epoch 14 Loss 0.2700\n",
      "Time taken for 1 epoch 103.56873726844788 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.2814\n",
      "Epoch 15 Batch 100 Loss 0.1986\n",
      "Epoch 15 Batch 200 Loss 0.2549\n",
      "Epoch 15 Batch 300 Loss 0.2577\n",
      "Epoch 15 Batch 400 Loss 0.2868\n",
      "Epoch 15 Loss 0.2531\n",
      "Time taken for 1 epoch 104.24980616569519 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2260\n",
      "Epoch 16 Batch 100 Loss 0.1892\n",
      "Epoch 16 Batch 200 Loss 0.2048\n",
      "Epoch 16 Batch 300 Loss 0.2492\n",
      "Epoch 16 Batch 400 Loss 0.2995\n",
      "Epoch 16 Loss 0.2362\n",
      "Time taken for 1 epoch 104.89053750038147 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2008\n",
      "Epoch 17 Batch 100 Loss 0.1725\n",
      "Epoch 17 Batch 200 Loss 0.1918\n",
      "Epoch 17 Batch 300 Loss 0.2311\n",
      "Epoch 17 Batch 400 Loss 0.2146\n",
      "Epoch 17 Loss 0.2234\n",
      "Time taken for 1 epoch 104.05299925804138 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1855\n",
      "Epoch 18 Batch 100 Loss 0.1989\n",
      "Epoch 18 Batch 200 Loss 0.2320\n",
      "Epoch 18 Batch 300 Loss 0.2253\n",
      "Epoch 18 Batch 400 Loss 0.2397\n",
      "Epoch 18 Loss 0.2104\n",
      "Time taken for 1 epoch 105.19219970703125 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1990\n",
      "Epoch 19 Batch 100 Loss 0.2003\n",
      "Epoch 19 Batch 200 Loss 0.1626\n",
      "Epoch 19 Batch 300 Loss 0.2461\n",
      "Epoch 19 Batch 400 Loss 0.2554\n",
      "Epoch 19 Loss 0.1989\n",
      "Time taken for 1 epoch 104.46099972724915 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1522\n",
      "Epoch 20 Batch 100 Loss 0.1652\n",
      "Epoch 20 Batch 200 Loss 0.1712\n",
      "Epoch 20 Batch 300 Loss 0.2291\n",
      "Epoch 20 Batch 400 Loss 0.2014\n",
      "Epoch 20 Loss 0.1891\n",
      "Time taken for 1 epoch 104.79357719421387 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(train_batches.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "            \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0d4e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "    def __init__(self, encoder, decoder, input_text_processor, output_text_processor):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.input_text_processor = input_text_processor\n",
    "        self.output_text_processor = output_text_processor\n",
    "        \n",
    "        self.output_token_string_from_index = (\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=output_text_processor.get_vocabulary(),\n",
    "                mask_token='',\n",
    "                invert=True))\n",
    "        \n",
    "        index_from_string = tf.keras.layers.StringLookup(\n",
    "            vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
    "        \n",
    "        token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
    "        \n",
    "        token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
    "        token_mask[np.array(token_mask_ids)] = True\n",
    "        self.token_mask = token_mask\n",
    "        \n",
    "        self.start_token = tf.cast(index_from_string(tf.constant('[START]')), dtype = tf.int32)\n",
    "        self.end_token = tf.cast(index_from_string(tf.constant('[END]')), dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb20e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_35196\\3203352847.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(\n",
    "    encoder= encoder,\n",
    "    decoder= decoder,\n",
    "    input_text_processor=input_text_processor,\n",
    "    output_text_processor=output_text_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46c7d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(self, result_tokens):\n",
    "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
    "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
    "                                       axis=-1, separator=' ')\n",
    "    result_text = tf.strings.strip(result_text)\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef39c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.tokens_to_text = tokens_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6ae8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_sample(self, sentence):\n",
    "    inputs = input_text_processor(sentence)\n",
    "    \n",
    "    inference_batch_size = tf.shape(inputs)[0]\n",
    "    \n",
    "    enc_start_state = [tf.fill([inference_batch_size, units], 0.), tf.fill([inference_batch_size,units], 0.)]\n",
    "\n",
    "    enc_out, enc_h, enc_c = self.encoder(inputs, enc_start_state)\n",
    "    \n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "    \n",
    "    start_tokens = tf.fill([inference_batch_size],  2)\n",
    "    end_token = 3 #output_text_processor.get_vocabulary().index('[END]')\n",
    "    \n",
    "    greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
    "    \n",
    "    decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.rnn_cell, \n",
    "                                                sampler=greedy_sampler, \n",
    "                                                output_layer=self.decoder.fc)\n",
    "    self.decoder.attention_mechanism.setup_memory(enc_out)\n",
    "    \n",
    "    decoder_initial_state = self.decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)\n",
    "    \n",
    "    decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
    "    \n",
    "    outputs, _, _ = decoder_instance(decoder_embedding_matrix, \n",
    "                                     start_tokens = start_tokens, \n",
    "                                     end_token= end_token, \n",
    "                                     initial_state=decoder_initial_state)\n",
    "    return outputs.sample_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29116b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_beam_search(self, sentence, beam_width = 3):\n",
    "    inputs = input_text_processor(sentence)\n",
    "    \n",
    "    inference_batch_size = tf.shape(inputs)[0]\n",
    "    \n",
    "    enc_start_state = [tf.fill([inference_batch_size, units], 0.), tf.fill([inference_batch_size,units], 0.)]\n",
    "    \n",
    "    enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)\n",
    "    \n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "    \n",
    "    start_tokens = tf.fill([inference_batch_size], self.start_token)\n",
    "    end_token = self.end_token\n",
    "    \n",
    "    enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n",
    "    decoder.attention_mechanism.setup_memory(enc_out)\n",
    "    print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 20, 1024]] :\", enc_out.shape)\n",
    "    \n",
    "    hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n",
    "    decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)\n",
    "    decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n",
    "    \n",
    "    decoder_instance = tfa.seq2seq.BeamSearchDecoder(decoder.rnn_cell,beam_width=beam_width, output_layer=decoder.fc)\n",
    "    decoder_embedding_matrix = decoder.embedding.variables[0]\n",
    "    \n",
    "    outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, start_tokens=start_tokens, end_token=end_token, initial_state=decoder_initial_state)\n",
    "    final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
    "    beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
    "\n",
    "    return final_outputs, beam_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2e420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.tf_beam_search = tf_beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c1fb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.tf_sample = tf_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22df9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "def __call__(self, sentence):\n",
    "    sample_id = self.tf_sample(sentence)\n",
    "    return self.tokens_to_text(sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4fdba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.__call__ = __call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e57b5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tf.constant([\n",
    "    \"Je veux un taxi près de l'aéroport\", \n",
    "    \"ou est la table\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51dd1c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b'i want a taxi about the airport . [END]',\n",
       "       b'where it is the table . [END] here .'], dtype=object)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = translator(input_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e84415df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "def beam_translate(self, sentence):\n",
    "    sample_id, scores = self.tf_beam_search(sentence)\n",
    "    scores = tf.reduce_sum(scores, axis = -1)\n",
    "    return self.tokens_to_text(sample_id), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89112e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translator.beam_translate = beam_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9b4f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 20, 1024]] : (None, 20, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=string, numpy=\n",
       "array([[b'i want a taxi to the airport . [END] [END]',\n",
       "        b'i want a taxi about the airport . [END] [END]',\n",
       "        b'i want a taxi about to the airport . [END]'],\n",
       "       [b'the table is the table . [END] [END] [END] [END]',\n",
       "        b'where it is the table . [END] [END] [END] [END]',\n",
       "        b'where he is the table . [END] [END] [END] [END]']], dtype=object)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, scores = translator.beam_translate(input_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "884564b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportTranslator(tf.Module):\n",
    "  def __init__(self, translator):\n",
    "    self.translator = translator\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string)])\n",
    "  def __call__(self, sentence):\n",
    "    result = self.translator(sentence)\n",
    "    return result\n",
    " \n",
    "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "  def beam_translate(self, sentence):\n",
    "    result, scores = self.translator.beam_translate(sentence)\n",
    "    scores = []\n",
    "    return result, scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b16ec9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = ExportTranslator(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5191a899",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 20, 1024]] : (None, 20, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, decoder_layer_call_fn, decoder_layer_call_and_return_conditional_losses, embedding_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: attention_translator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: attention_translator\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(translator, export_dir = \"attention_translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21604687",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load(\"attention_translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09225adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b'i want a taxi about the airport . [END]',\n",
       "       b'where it is the table . [END] here .'], dtype=object)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e99552c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3), dtype=string, numpy=\n",
       " array([[b'i want a taxi to the airport . [END] [END]',\n",
       "         b'i want a taxi about the airport . [END] [END]',\n",
       "         b'i want a taxi about to the airport . [END]'],\n",
       "        [b'the table is the table . [END] [END] [END] [END]',\n",
       "         b'where it is the table . [END] [END] [END] [END]',\n",
       "         b'where he is the table . [END] [END] [END] [END]']], dtype=object)>,\n",
       " [])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded.beam_translate(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2280cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
